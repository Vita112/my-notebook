#### 1. 论文列表1

- Navon,  D. (1977).  Forest before trees:  The precedence of global features in visual perception.

- McClelland, J. L. and Rumelhart, D. E. (1981).  An interactive activation model of context effects in letter perception:  I. an account of basic findings.

- Plaut, D. C., McClelland, J. L., Seidenberg, M. S., and Patterson, K. (1996). Understanding normal and impaired word reading:  computational principles in quasi-regular domains.

- Marcus, G. (2001).  The algebraic mind.

- Goodwin, G. P. and Johnson-Laird, P. (2005).  Reasoning about relations.Psychological 

- Kemp, C. and Tenenbaum, J. B. (2008).  The discovery of structural form.

- Botvinick,  M.  M.  (2008).   Hierarchical  models  of  behavior  and  prefrontal  function.

- Tenenbaum, J. B., Kemp, C., Griffiths, T. L., and Goodman, N. D. (2011).  How to grow a mind:

  Statistics, structure, and abstraction

#### 2. 论文列表2

- Shalev-Shwartz, S., Shamir, O., and Shammah, S. (2017).  Failures of gradient-based deep learning

- Lake, B. M., Ullman, T. D., Tenenbaum, J. B., and Gershman, S. J. (2017).  Building machines that learn and think like people.

- Lake, B. M. and Baroni, M. (2018).  Still not systematic after all these years:  On the compositional skills of sequence-to-sequence recurrent networks. 

- Marcus, G. (2018a).  Deep learning:  A critical appraisal.

- Pearl, J. (2018).  Theoretical impediments to machine learning with seven sparks from the causal revolution.

  Yuille, A. L. and Liu, C. (2018).  Deep nets:  What have they ever done for vision?

#### 3. 论文列表3

- Smolensky, P. (1990). Tensor product variable binding and the representation of symbolic structures in connectionist systems.
- Hinton,  G.  E.  (1990).   Mapping  part-whole  hierarchies  into  connectionist  networks.
- Pollack, J. B. (1990).  Recursive distributed representations.
- Elman,  J. L. (1991).  Distributed representations,  simple recurrent networks,  and grammatical structure.
- Plate, T. A. (1995).  Holographic reduced representations.
- Eliasmith, C. (2013). How to build a brain:  A neural architecture for biological cognition
- Marcus, G. (2001).  The algebraic mind.

#### 4. 论文列表4

- Mikolov, T., Yih, W.-t., and Zweig, G. (2013).  Linguistic regularities in continuous space word representations. 
- Pennington, J., Socher, R., and Manning, C. (2014).  Glove:  Global vectors for word representation.
- Narayanan, A., Chandramohan, M., Venkatesan, R., Chen, L., Liu, Y., and Jaiswal, S. (2017). graph2vec:  Learning distributed representations of graphs
- Allamanis,  M.,  Chanthirasegaran,  P.,  Kohli,  P.,  and  Sutton,  C.  (2017).   Learning  continuous semantic representations of symbolic expressions.  
- Evans, R., Saxton, D., Amos, D., Kohli, P., and Grefenstette, E. (2018).  Can neural networks understand  logical  entailment? 
- Farquhar, G., Rockt ̈aschel, T., Igl, M., and Whiteson, S. (2018). TreeQN and ATreeC: Differentiabletree planning for deep reinforcement learning. 
- Devlin, J., Uesato, J., Singh, R., and Kohli, P. (2017).  Semantic code repair using neuro-symbolic transformation networks.

#### 5. 论文列表5

- Reed,  S.  and  De  Freitas,  N.  (2016).   Neural  programmer-interpreters.   
- Garnelo, M., Arulkumaran, K., and Shanahan, M. (2016).  Towards deep symbolic reinforcement learning.
- Ritchie, D., Horsfall, P., and Goodman, N. D. (2016).  Deep amortized inference for probabilistic programs
- Wu, J., Lu, E., Kohli, P., Freeman, B., and Tenenbaum, J. (2017).  Learning to see physics via visual de-animation. 
- Denil, M., Colmenarejo, S. G., Cabi, S., Saxton, D., and de Freitas, N. (2017).  Programmable agents.
- Hudson, D. A. and Manning, C. D. (2018). Compositional attention networks for machine reasoning.

#### 6. 论文列表6

- Garcia, V. and Bruna, J. (2018). Few-shot learning with graph neural networks. 

  > multi-agent systems

- Kipf, T., Fetaya, E., Wang, K.-C., Welling, M., and Zemel, R. (2018). Neural relational inference for interacting systems. 

  > reason about knowledge graphs 

- Hamaguchi, T., Oiwa, H., Shimbo, M., and Matsumoto, Y. (2017).  Knowledge transfer for out-of-knowledge-base entities:  A graph neural network approach.

- O ̃noro-Rubio,  D.,  Niepert,  M.,  Garc ́ıa-Dur ́an,  A.,  Gonz ́alez-S ́anchez,  R.,  and  L ́opez-Sastre,R. J. (2017).  Representation learning for visual-relational knowledge graphs.

  > model-free  &  model-based  &  model-free reinforcement learning

- Wang, T., Liao, R., Ba, J., and Fidler, S. (2018b).  Nervenet:  Learning structured policy with graph neural networks.

- Sanchez-Gonzalez, A., Heess, N., Springenberg, J. T., Merel, J., Riedmiller, M., Hadsell, R., andBattaglia, P. (2018).  Graph networks as learnable physics engines for inference and control

- Zambaldi, V., Raposo, D., Santoro, A., Bapst, V., Li, Y., Babuschkin, I., Tuyls, K., Reichert, D.,Lillicrap, T., Lockhart, E., Shanahan, M., Langston, V., Pascanu, R., Botvinick, M., Vinyals, O.,and Battaglia, P. (2018).  Relational deep reinforcement learning.

- Hamrick, J., Allen, K., Bapst, V., Zhu, T., McKee, K., Tenenbaum, J., and Battaglia, P. (2018). Relational inductive bias for physical construction in humans and machines. 


#### 7. 论文列表7

- Dai,  H.,  Khalil,  E.  B.,  Zhang,  Y.,  Dilkina,  B.,  and  Song,  L.  (2017).   Learning  combinatorial optimization algorithms over graphs. 

- Selsam, D., Lamm, M., Bunz, B., Liang, P., de Moura, L., and Dill, D. L. (2018).  Learning a sat

  solver from single-bit supervision.

- Yoon,  K.,  Liao,  R.,  Xiong,  Y.,  Zhang,  L.,  Fetaya,  E.,  Urtasun,  R.,  Zemel,  R.,  and Pitkow,  X.

  (2018).  Inference in probabilistic graphical models by graph neural networks.

- Bojchevski, A., Shchur, O., Z ̈ugner, D., and G ̈unnemann, S. (2018).  Netgan:  Generating graphs via

  random walks.

#### 8. 论文列表8

- Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., and Monfardini, G. (2009a).  Computational

  capabilities of graph neural networks

- Bronstein, M. M., Bruna, J., LeCun, Y., Szlam, A., and Vandergheynst, P. (2017).  Geometric deep

  learning:  going beyond euclidean data.

- Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., and Dahl, G. E. (2017).  Neural message

  passing for quantum chemistry.

- Wang, X., Girshick, R., Gupta, A., and He, K. (2018c).  Non-local neural networks

- Veliˇckovi ́c, P., Cucurull, G., Casanova, A., Romero, A., Li`o, P., and Bengio, Y. (2018).  Graph

  attention networks


#### 9. 论文列表9

- full GN block 
  - Hamrick, J., Allen, K., Bapst, V., Zhu, T., McKee, K., Tenenbaum, J., and Battaglia, P. (2018). Relational inductive bias for physical construction in humans and machines.  
  - Sanchez-Gonzalez, A., Heess, N., Springenberg, J. T., Merel, J., Riedmiller, M., Hadsell, R., and Battaglia, P. (2018).  Graph networks as learnable physics engines for inference and control.  
- Independent, recurrent update block
  - Sanchez-Gonzalez, A., Heess, N., Springenberg, J. T., Merel, J., Riedmiller, M., Hadsell, R., and Battaglia, P. (2018).  Graph networks as learnable physics engines for inference and control.  
- MPNN 
  - Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., and Dahl, G. E. (2017).  Neural message passing for quantum chemistry.
- NLNN
  - Wang, X., Girshick, R., Gupta, A., and He, K. (2018c).  Non-local neural networks.  
- Relation network 
  - Raposo, D., Santoro, A., Barrett, D., Pascanu, R., Lillicrap, T., and Battaglia, P. (2017). Discovering objects and their relations from entangled scene representations. 
  - Santoro, A., Raposo, D., Barrett, D. G., Malinowski, M., Pascanu, R., Battaglia, P., and Lillicrap, T. (2017).  A simple neural network module for relational reasoning.  
- Deep Set
  - Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R. R., and Smola, A. J. (2017). Deep sets. 




#### 10. 论文列表10

- Battaglia, P., Pascanu, R., Lai, M., Rezende, D. J., et al. (2016).  Interaction networks for learning about objects, relations and physics. 
- Sanchez-Gonzalez, A., Heess, N., Springenberg, J. T., Merel, J., Riedmiller, M., Hadsell, R., and Battaglia, P. (2018).  Graph networks as learnable physics engines for inference and control.  
- Hamrick, J., Allen, K., Bapst, V., Zhu, T., McKee, K., Tenenbaum, J., and Battaglia, P. (2018). Relational inductive bias for physical construction in humans and machines. 
- Bello, I., Pham, H., Le, Q. V., Norouzi, M., and Bengio, S. (2016). Neural combinatorial optimization with reinforcement learning.
- Hamilton, W., Ying, Z., and Leskovec, J. (2017).  Inductive representation learning on large graphs.

#### 11. 论文列表11

- Tenenbaum, J. B., Kemp, C., Griffiths, T. L., and Goodman, N. D. (2011).  How to grow a mind: Statistics, structure, and abstraction. **Science**
- Lake,  B. M.,  Salakhutdinov,  R.,  and Tenenbaum,  J. B. (2015).   Human-level concept learning through probabilistic program induction.  **Science**
- Goodman,  N. D.,  Tenenbaum,  J. B.,  and Gerstenberg,  T. (2015).   Concepts in a probabilistic language of thought. 

#### 12. 论文列表12

